{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af5b912f",
   "metadata": {},
   "source": [
    "# Linear Algebra in NumPy\n",
    "\n",
    "### What is Linear Algebra?\n",
    "\n",
    "Linear algebra is the branch of mathematics that helps us understand and work with structured numerical data. It deals with vectors (which are like one-dimensional lists of numbers), matrices (which are like tables or grids of numbers), and higher-dimensional arrays. These structures are used to represent data, relationships, and transformations — which are all critical in fields like machine learning, computer graphics, and AI.\n",
    "\n",
    "We use linear algebra to handle tasks like rotating images, transforming datasets, compressing information, and solving systems of equations. In machine learning, almost everything — from data input to model weights to predictions — is represented as vectors and matrices. When we train models, we're often multiplying matrices together, adjusting weights, and analyzing patterns. The math behind this — vector addition, matrix multiplication, transposition, inversion, and eigen decomposition — is all part of linear algebra.\n",
    "\n",
    "Understanding these operations helps us design algorithms, optimize performance, and extract insights from data. Whether it's recognizing faces in images, predicting stock prices, or translating text, the foundation is often built using the concepts of linear algebra\n",
    "\n",
    "### Key Concepts & Operations in Linear Algebra\n",
    "\n",
    "1. **Dot Product (`np.dot()` or `@`)**\n",
    "    \n",
    "    The dot product is an operation where we multiply corresponding elements of two arrays and sum the result. This operation is used in many AI models to calculate similarity between vectors or to combine inputs with weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a54255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Product: 11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "    \n",
    "a = np.array([1, 2])\n",
    "b = np.array([3, 4])\n",
    "    \n",
    "dot = np.dot(a, b)  # or a @ b\n",
    "print(\"Dot Product:\", dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10159f4",
   "metadata": {},
   "source": [
    "2. **Matrix Multiplication (`np.matmul()` or `@`)**\n",
    "    \n",
    "    Matrix multiplication lets us combine rows of one matrix with columns of another. This is the backbone of all neural network computations — inputs get multiplied by weights layer by layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be19217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Multiplication:\n",
      " [[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "    \n",
    "result = np.matmul(A, B)\n",
    "print(\"Matrix Multiplication:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6d65d",
   "metadata": {},
   "source": [
    "3. **Transpose of a Matrix (`.T` or `np.transpose()`)**\n",
    "    \n",
    "    Transposing a matrix means flipping its rows and columns. We often do this when reshaping data or preparing matrices for multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "459f08b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.array([[1, 2], [3, 4]])\n",
    "transposed = matrix.T\n",
    "print(transposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f305b9d",
   "metadata": {},
   "source": [
    "4. **Inverse of a Matrix (`np.linalg.inv()`)**\n",
    "    \n",
    "    The inverse of a matrix is the equivalent of \"dividing\" by that matrix. Only square matrices that are non-singular (i.e., have a non-zero determinant) have an inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0279010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse:\n",
      " [[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import inv\n",
    "    \n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "A_inv = inv(A)\n",
    "print(\"Inverse:\\n\", A_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05e4938",
   "metadata": {},
   "source": [
    "5. **Determinant (`np.linalg.det()`)**\n",
    "    \n",
    "    The determinant is a scalar value that tells us if a matrix is invertible. If the determinant is zero, the matrix can’t be inverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d17fe312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinant: -2.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import det\n",
    "    \n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "print(\"Determinant:\", det(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de66168",
   "metadata": {},
   "source": [
    "6. **Eigenvalues & Eigenvectors (`np.linalg.eig()`)**\n",
    "    \n",
    "    These represent the \"direction\" and \"scale\" of how data is transformed. We use them in dimensionality reduction techniques like PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42851872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues:\n",
      " [3. 2.]\n",
      "Eigenvectors:\n",
      " [[0.89442719 0.70710678]\n",
      " [0.4472136  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import eig\n",
    "    \n",
    "A = np.array([[4, -2], [1, 1]])\n",
    "vals, vecs = eig(A)\n",
    "print(\"Eigenvalues:\\n\", vals)\n",
    "print(\"Eigenvectors:\\n\", vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a038fbd",
   "metadata": {},
   "source": [
    "### AI/ML Use Cases of Linear Algebra\n",
    "\n",
    "| Linear Algebra Concept | Real-World Use Case |\n",
    "| --- | --- |\n",
    "| Dot Product | Similarity Search, Attention |\n",
    "| Matrix Multiplication | Neural Networks, Word Embeddings |\n",
    "| Transpose | Tensor Reshaping |\n",
    "| Inverse Matrix | Optimization, Solving Equations |\n",
    "| Eigenvalues/Vectors | PCA, Dimensionality Reduction |\n",
    "| Determinant | Invertibility Checks |\n",
    "\n",
    "### Exercises\n",
    "\n",
    "Q1. Compute the dot product of two vectors: `[1, 2, 3]` and `[4, 5, 6]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "892c42df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using np.dot(): 32\n",
      "Using @ operator: 32\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "\n",
    "dot_pro1 = np.dot(a, b)\n",
    "dot_pro2 = a @ b\n",
    "print(f'Using np.dot(): {dot_pro1}')\n",
    "print(f'Using @ operator: {dot_pro2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240caff9",
   "metadata": {},
   "source": [
    "Q2. Multiply two 2x2 matrices using `@` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e87aa6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Multiplication Result:\n",
      "[[3600 4100]\n",
      " [6400 7300]]\n"
     ]
    }
   ],
   "source": [
    "c = np.array([[20,30], [40,50]])\n",
    "d = np.array([[60,70], [80,90]])\n",
    "\n",
    "matrix_multiplication = c @ d\n",
    "print(f'Matrix Multiplication Result:\\n{matrix_multiplication}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e682d",
   "metadata": {},
   "source": [
    "Q3. Find the transpose and inverse of `[[2, 1], [5, 3]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fd9d7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpose:\n",
      " [[2 5]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "e = np.array([[2, 1], [5, 3]])\n",
    "tarnsposed = e.T\n",
    "print('Transpose:\\n',tarnsposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f7d354",
   "metadata": {},
   "source": [
    "Q4. Find the determinant and eigenvalues of matrix `[[1, 2], [2, 1]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa87c318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues:\n",
      " [ 3. -1.]\n",
      "Eigenvectors:\n",
      " [[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import eig\n",
    "\n",
    "f = np.array([[1, 2], [2, 1]])\n",
    "eigenvalues, eigenvectors = eig(f)\n",
    "print('Eigenvalues:\\n', eigenvalues)\n",
    "print('Eigenvectors:\\n', eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9747be04",
   "metadata": {},
   "source": [
    "Q5. Create a matrix `A` and verify if `A @ A_inv = I` (identity matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fc9b56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity Matrix (float result):\n",
      " [[1.0000000e+00 0.0000000e+00]\n",
      " [8.8817842e-16 1.0000000e+00]]\n",
      "Identity Matrix (rounded to int):\n",
      " [[1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "A_inv = np.linalg.inv(A)\n",
    "\n",
    "# Float result of A @ A_inv\n",
    "identity_float = A @ A_inv\n",
    "print(\"Identity Matrix (float result):\\n\", identity_float)\n",
    "\n",
    "# Rounded to nearest integer for clean display\n",
    "identity_int = np.rint(identity_float).astype(int)\n",
    "print(\"Identity Matrix (rounded to int):\\n\", identity_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa2545",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Linear Algebra plays a central role in modern machine learning, data science, and AI workflows. It helps us represent and transform data using vectors and matrices. With NumPy, we can perform all key linear algebra operations like dot products, matrix multiplication, transpose, inverse, determinant, and eigen decomposition — all essential tools when working with high-dimensional datasets and neural networks.\n",
    "\n",
    "The dot product is widely used for calculating similarity, projecting vectors, and building neural network operations. Matrix multiplication is the foundation of linear layers, while the transpose lets us align dimensions for valid multiplications. The inverse helps solve equations in optimization problems. The determinant gives insight into a matrix’s properties, like whether it's invertible. Eigenvalues and eigenvectors help us reduce dimensionality and understand the underlying structure of data through techniques like PCA.\n",
    "\n",
    "By learning these operations in NumPy, we can build powerful models and perform numerical computations with ease. These concepts not only help us manipulate data efficiently but also form the theoretical base of algorithms that power real-world AI systems. Understanding how these matrix-based transformations work gives us better control over model behavior, optimization, and interpretability — all of which are crucial for developing intelligent, robust solutions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
