{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb091771",
   "metadata": {},
   "source": [
    "# Duplicate Data Management in Pandas\n",
    "\n",
    "### What Are Duplicate Values?\n",
    "\n",
    "Duplicate values in a dataset are rows that are **exact copies** of other rows â€” meaning every value across all columns is the same. For example, if the Titanic dataset mistakenly includes two identical entries for the same passenger, it inflates row counts and can **skew statistics**, affect model training, and create **data leakage**.\n",
    "\n",
    "Duplicates usually happen due to:\n",
    "\n",
    "- Data entry errors\n",
    "- Accidental merges or joins\n",
    "- Sensor or API bugs\n",
    "- Appending the same data twice\n",
    "\n",
    "Detecting and removing duplicates is part of every serious **data cleaning pipeline**. Pandas gives us powerful tools like `.duplicated()` and `.drop_duplicates()` to identify and eliminate them.\n",
    "\n",
    "### Why Managing Duplicates Is Important\n",
    "\n",
    "Duplicate data may not seem harmful at first glance, but in the context of **machine learning and analytics**, it can have serious consequences:\n",
    "\n",
    "- **Skewed distributions**: Repeated values distort averages, medians, and standard deviations.\n",
    "- **Biased models**: Training models on repeated examples can lead to overfitting.\n",
    "- **Inaccurate insights**: Aggregations like `.mean()` or `.value_counts()` become misleading.\n",
    "- **Data integrity issues**: Repeating entities (e.g., duplicate users) leads to false conclusions.\n",
    "\n",
    "In AI/ML projects, duplicates **inflate confidence**, introduce **data leakage**, and can **degrade model performance**. Cleaning them early ensures that our models **learn patterns from true diversity** in the data, not artificial repetition.\n",
    "\n",
    "### Common Methods for Detecting Duplicates\n",
    "\n",
    "**`.duplicated()`**\n",
    "\n",
    "Returns a boolean Series marking duplicated rows (default checks all columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32074250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# Detect duplicated rows\n",
    "duplicates = df.duplicated()\n",
    "print(duplicates.sum())  # Total duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2286c0",
   "metadata": {},
   "source": [
    "**`.duplicated(subset=...)`**\n",
    "\n",
    "Check duplicates based on specific columns only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4945ed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates by 'Name' and 'Ticket'\n",
    "print(df.duplicated(subset=['Name', 'Ticket']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd32894",
   "metadata": {},
   "source": [
    "### Removing Duplicates with `.drop_duplicates()`\n",
    "\n",
    "Once duplicates are detected, we can **remove them safely** using `.drop_duplicates()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ef5941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Drop all completely duplicated rows\n",
    "df = df.drop_duplicates()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1de054",
   "metadata": {},
   "source": [
    "Or drop based on certain columns only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db83c389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Drop based on a subset (keep first occurrence)\n",
    "df = df.drop_duplicates(subset=['Name', 'Ticket'], keep='first')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01da7e76",
   "metadata": {},
   "source": [
    "By default, `keep='first'` keeps the first occurrence and drops others. You can also use:\n",
    "\n",
    "- `keep='last'`: keeps the last duplicate\n",
    "- `keep=False`: drops all duplicates entirely\n",
    "\n",
    "### Duplicates and Indexes\n",
    "\n",
    "Sometimes duplicates appear in **index labels** rather than rows. Use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563d498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False]\n"
     ]
    }
   ],
   "source": [
    "print(df.index.duplicated()[:5])  # Check if index is duplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba94826",
   "metadata": {},
   "source": [
    "To reset duplicate indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59685ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc196a8",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Q1. Count total duplicated rows (fully identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0977d6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05e3b4a",
   "metadata": {},
   "source": [
    "Q2. Drop all duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b3b6d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0768aa17",
   "metadata": {},
   "source": [
    "Q3. Drop duplicates based on 'Name' and 'Ticket' (keep first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "346cbe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['Name', 'Ticket'], keep='first')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc06f9",
   "metadata": {},
   "source": [
    "Q4. Drop all duplicates entirely (no duplicates kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dd3a841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(keep=False)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Check for duplicated index labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc1c7072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.index.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c4a630",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Duplicate data is a **silent data quality killer**. Itâ€™s easy to overlook, but in analysis and machine learning, it can seriously mislead results and damage model accuracy. Pandas offers us fast and flexible tools to **detect**, **analyze**, and **remove** these repeated records.\n",
    "\n",
    "We learned that `.duplicated()` marks repeated rows, while `.drop_duplicates()` removes them â€” either entirely or based on selected columns. The `keep` parameter gives us control over which duplicates to retain. We also covered how to handle duplicate **indexes**, a common issue in messy merges.\n",
    "\n",
    "Always analyze **why** duplicates exist before removing them â€” sometimes repetition is intentional (e.g., transactions), and sometimes it signals data errors.\n",
    "\n",
    "With clean, deduplicated data, we build models that are more **trustworthy**, **fair**, and **robust**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
