{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf17211a",
   "metadata": {},
   "source": [
    "# Performance Optimization and Memory Management in Pandas\n",
    "\n",
    "### What Is Performance Optimization and Memory Management?\n",
    "\n",
    "When working with small datasets like the Titanic CSV, performance isn’t usually an issue. But in real-world machine learning and data engineering projects, we'll often deal with **large datasets** — sometimes in gigabytes. Poor handling of these can cause **slowdowns, crashes, or memory overload**.\n",
    "\n",
    "Pandas provides **efficient strategies** for memory reduction and performance improvements, such as:\n",
    "\n",
    "- Optimizing data types\n",
    "- Using vectorized operations\n",
    "- Chunked loading\n",
    "- Avoiding unnecessary copies\n",
    "- Efficient filtering and joins\n",
    "\n",
    "Mastering these practices ensures our data pipeline is **fast, scalable, and production-ready**.\n",
    "\n",
    "## Techniques for Performance & Memory Efficiency\n",
    "\n",
    "1. **Downcast Numeric Types**\n",
    "    \n",
    "Instead of default `float64` or `int64`, use smaller types if possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "print(pd.to_numeric(df['Age'], downcast='float'))\n",
    "print(pd.to_numeric(df['Pclass'], downcast='integer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cc382e",
   "metadata": {},
   "source": [
    "Use `.info()` to check reduced memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c112cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info(memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac091db",
   "metadata": {},
   "source": [
    "2. **Convert Object to Category**\n",
    "    \n",
    "For columns with **repeated string values**, convert to `category`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Sex'].astype('category'))\n",
    "print(df['Embarked'].astype('category'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69492e14",
   "metadata": {},
   "source": [
    "his greatly reduces memory use for low-cardinality columns.\n",
    "    \n",
    "3. **Use Chunking for Large Files**\n",
    "    \n",
    "Instead of loading entire CSVs into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c977c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_iter = pd.read_csv(\"data/train.csv\", chunksize=1000)\n",
    "for chunk in chunk_iter:\n",
    "    process(chunk)  # Apply logic to each chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1943db77",
   "metadata": {},
   "source": [
    "This is essential for working with **big data files**.\n",
    "    \n",
    "4. **Vectorized Operations over Loops**\n",
    "    \n",
    "Avoid loops — use vectorized operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dffff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad (slow)\n",
    "for i in range(len(df)):\n",
    "    df.loc[i, 'Is_Adult'] = df.loc[i, 'Age'] >= 18\n",
    "    \n",
    "# Good (fast)\n",
    "df['Is_Adult'] = df['Age'] >= 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f22bc4",
   "metadata": {},
   "source": [
    "5. **Drop Unused Columns Early**\n",
    "    \n",
    "Remove irrelevant data immediately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc576b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.drop(columns=['Cabin', 'Ticket'], inplace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a5ca58",
   "metadata": {},
   "source": [
    "This saves memory and speeds up operations.\n",
    "    \n",
    "6. Use `inplace=True` Carefully\n",
    "    \n",
    "In-place operations save memory by avoiding copies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dropna(inplace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af22bc5",
   "metadata": {},
   "source": [
    "But be careful: they **modify original data** and may cause errors in chained operations.\n",
    "    \n",
    "7. Profile our Memory\n",
    "    \n",
    "Use `df.memory_usage(deep=True)` to inspect column-by-column memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd1b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.memory_usage(deep=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14399761",
   "metadata": {},
   "source": [
    "Or use `pandas-profiling` or `memory_profiler` for visual profiling.\n",
    "    \n",
    "\n",
    "### AI/ML Use Case: Scaling Model Pipelines\n",
    "\n",
    "In machine learning:\n",
    "\n",
    "- Datasets grow during feature engineering.\n",
    "- Efficient preprocessing avoids out-of-memory errors.\n",
    "- Data types matter in serialization (`.csv`, `.parquet`, `.joblib`).\n",
    "- Downcasting speeds up training and reduces file size.\n",
    "\n",
    "This is especially important for **automated pipelines**, **cloud deployments**, or **large ML experiments**.\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Q1. Check memory usage of the Titanic DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0104bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info(memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f9b6e0",
   "metadata": {},
   "source": [
    "Q2. Downcast Fare and Age columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11014af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fare'] = pd.to_numeric(df['Fare'], downcast='float')\n",
    "df['Age'] = pd.to_numeric(df['Age'], downcast='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b354c0",
   "metadata": {},
   "source": [
    "Q3. Convert Embarked and Sex to category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ddeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'] = df['Embarked'].astype('category')\n",
    "df['Sex'] = df['Sex'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65003edc",
   "metadata": {},
   "source": [
    "Q4. Load a CSV in chunks of 500 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d579d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_iter = pd.read_csv(\"data/train.csv\", chunksize=500)\n",
    "for chunk in chunk_iter:\n",
    "    print(chunk.head(1))  # Print only one row per chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96383af",
   "metadata": {},
   "source": [
    "Q5. Measure column-wise memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.memory_usage(deep=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7339c65",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Performance optimization and memory management in Pandas are **not just for big data engineers** — they are essential skills for **any serious data scientist**. As our datasets grow, small inefficiencies multiply and can lead to bottlenecks or crashes.\n",
    "\n",
    "By using **smaller data types**, **vectorized logic**, **categorical encodings**, and **chunked processing**, we can significantly reduce memory use and make our code run faster. Efficient code is not only better for production, but also improves experiment speed during model development.\n",
    "\n",
    "Treat these practices as **foundations of professional-grade data work** — especially if we aim to deploy models, scale pipelines, or collaborate in team environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
