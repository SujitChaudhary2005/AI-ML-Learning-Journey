{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1d918a",
   "metadata": {},
   "source": [
    "# Basic Data Exploration\n",
    "\n",
    "### What is Basic Data Exploration?\n",
    "\n",
    "Before we analyze, visualize, or build models with our data, we must first understand what we’re working with. That’s where **basic data exploration** comes in. This is our very first step in any data science or machine learning project. When we open a dataset like Titanic, we want to quickly check how many rows and columns it has, what kinds of values are stored in each column, whether the data looks clean, and if there are any surprises — like missing values, incorrect types, or weird outliers. We don’t need to read the entire file manually; instead, we use built-in Pandas tools to get a strong first impression.\n",
    "\n",
    "Using simple and powerful commands like `.head()`, `.tail()`, `.info()`, `.describe()`, and `.shape`, we can uncover the structure, quality, and summary statistics of our dataset within seconds. These methods form the backbone of every Exploratory Data Analysis (EDA) workflow. They help us decide what to clean, what to visualize, and what to use in our models. We’re not trying to draw conclusions at this point — just trying to **understand** the data so we can make the right choices moving forward. Every good AI/ML workflow starts with this step, and the stronger our grasp here, the better our results later.\n",
    "\n",
    "### `.head()` and `.tail()`: Previewing Our Dataset\n",
    "\n",
    "When we load a new dataset, we usually don’t want to print the entire thing. Instead, we use `.head()`to preview the **first few rows**. By default, it shows us the top 5 rows, which is enough to check whether our data loaded correctly. We can confirm that column names are recognized, that data values look realistic, and that nothing broke during the loading process. For example, in the Titanic dataset, we can see how passenger information is stored — including names, age, ticket class, fare, and more.\n",
    "\n",
    "Similarly, `.tail()` shows us the **last few rows** of the DataFrame. This helps us verify the end of the file, check for empty rows, or look at recently added records. Together, `.head()` and `.tail()` give us a complete view from both the top and bottom — making sure we’re not missing anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa041298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"file_name.csv\") \n",
    "\n",
    "print(df.head())   # View first 5 rows\n",
    "print(df.tail(3))  # View last 3 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43a9d5",
   "metadata": {},
   "source": [
    "### `.shape`: Checking the Size of Our Dataset\n",
    "\n",
    "The `.shape` attribute gives us the number of **rows and columns** in our DataFrame. This is important because it tells us how big our dataset is — whether it has a few records or thousands. In the Titanic dataset, we might get something like `(891, 12)`, which means we have 891 rows and 12 columns.\n",
    "\n",
    "Knowing the shape helps us plan ahead. If we’re working with 100,000+ rows, we might want to sample. If we only have 10 rows, we might manually review them. Later, when we clean data or drop columns, checking `.shape` confirms that changes happened correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd56a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c5016",
   "metadata": {},
   "source": [
    "### `.info()`: Getting the Structure and Data Types\n",
    "\n",
    "The `.info()` method is one of the most useful tools when we first load a dataset. It gives us a detailed overview of **each column**: the name, data type (`int`, `float`, `object`, etc.), and how many non-null values are present. This helps us quickly spot **missing values** and understand whether our data types are what we expect.\n",
    "\n",
    "For instance, if the \"Age\" column has 714 non-null values but our dataset has 891 rows, we know that some ages are missing. Also, if we find a column that should be numeric but is marked as `object`, it means we need to clean or convert it. Understanding the structure early helps us avoid bugs and errors later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a9ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb0c2f",
   "metadata": {},
   "source": [
    "### `.describe()`: Summarizing Numerical Columns\n",
    "\n",
    "To quickly explore all numeric columns, we use `.describe()`. It gives us useful statistics like **mean**, **standard deviation**, **minimum and maximum**, and the 25th, 50th (median), and 75th percentiles. This tells us whether a feature is skewed, whether it has outliers, and how values are distributed.\n",
    "\n",
    "For example, in the Titanic dataset, we can use `.describe()` to understand the distribution of fares. If the max fare is much higher than the 75th percentile, that could indicate outliers. We also see how many people have values in each column. These summaries are critical when we’re preparing features for machine learning, scaling values, or detecting anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3928d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c54e03",
   "metadata": {},
   "source": [
    "We can also summarize **non-numeric (object) columns** like names or categories using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c6256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0fc461",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Q1. Load the Titanic dataset and use `.head()` to display the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220ea767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "5            6         0       3   \n",
      "6            7         0       1   \n",
      "7            8         0       3   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "5                                   Moran, Mr. James    male   NaN      0   \n",
      "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "5      0            330877   8.4583   NaN        Q  \n",
      "6      0             17463  51.8625   E46        S  \n",
      "7      1            349909  21.0750   NaN        S  \n",
      "8      2            347742  11.1333   NaN        S  \n",
      "9      0            237736  30.0708   NaN        C  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de424a",
   "metadata": {},
   "source": [
    "Q2. Use `.tail()` to display the last 7 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05648a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass                                      Name  \\\n",
      "884          885         0       3                    Sutehall, Mr. Henry Jr   \n",
      "885          886         0       3      Rice, Mrs. William (Margaret Norton)   \n",
      "886          887         0       2                     Montvila, Rev. Juozas   \n",
      "887          888         1       1              Graham, Miss. Margaret Edith   \n",
      "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "889          890         1       1                     Behr, Mr. Karl Howell   \n",
      "890          891         0       3                       Dooley, Mr. Patrick   \n",
      "\n",
      "        Sex   Age  SibSp  Parch           Ticket    Fare Cabin Embarked  \n",
      "884    male  25.0      0      0  SOTON/OQ 392076   7.050   NaN        S  \n",
      "885  female  39.0      0      5           382652  29.125   NaN        Q  \n",
      "886    male  27.0      0      0           211536  13.000   NaN        S  \n",
      "887  female  19.0      0      0           112053  30.000   B42        S  \n",
      "888  female   NaN      1      2       W./C. 6607  23.450   NaN        S  \n",
      "889    male  26.0      0      0           111369  30.000  C148        C  \n",
      "890    male  32.0      0      0           370376   7.750   NaN        Q  \n"
     ]
    }
   ],
   "source": [
    "print(data.tail(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8706e3",
   "metadata": {},
   "source": [
    "Q3. Use `.shape` to find out how many rows and columns the dataset has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce45b73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d45a2c1",
   "metadata": {},
   "source": [
    "Q4. Use `.info()` to check which columns contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb072c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c2648",
   "metadata": {},
   "source": [
    "Q5. Use `.describe()` to summarize the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a126a397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee645177",
   "metadata": {},
   "source": [
    "Q6. Use `.describe(include='object')` to explore non-numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96f831c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Name   Sex  Ticket Cabin Embarked\n",
      "count                       891   891     891   204      889\n",
      "unique                      891     2     681   147        3\n",
      "top     Braund, Mr. Owen Harris  male  347082    G6        S\n",
      "freq                          1   577       7     4      644\n"
     ]
    }
   ],
   "source": [
    "print(data.describe(include='object'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5446b381",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "When we begin working with any dataset — whether it's for learning, analysis, or building AI models — we always start with basic data exploration. This stage helps us understand what we’re dealing with. The `.head()` and `.tail()` methods give us a quick look at the start and end of the data. The `.shape` property tells us the dataset’s size. The `.info()` method helps us see what kind of data we have and whether anything is missing. The `.describe()` method summarizes all numerical values so we can spot trends, outliers, or unusual distributions.\n",
    "\n",
    "Together, these tools help us prepare our minds for deeper analysis. We start to see patterns, detect problems, and figure out what needs to be cleaned or transformed. As we move toward visualization, modeling, and prediction, this foundation will guide our decisions. If we skip this step, we risk building models on broken or misunderstood data. But when we do it right — when we explore our data carefully — everything else becomes easier and more reliable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
