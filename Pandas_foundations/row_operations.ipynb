{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8790ca97",
   "metadata": {},
   "source": [
    "# Row Operations in Pandas\n",
    "\n",
    "### What Are Row Operations?\n",
    "\n",
    "Row operations in Pandas involve modifying the rows of a DataFrame — including **adding new rows**, **removing rows**, **reordering or selecting specific rows**, and **sampling random rows**. Each row typically represents one observation, such as a single passenger on the Titanic. So manipulating rows directly affects the shape, content, and meaning of our dataset.\n",
    "\n",
    "These operations are often used in:\n",
    "\n",
    "- **Cleaning** data (removing unwanted records),\n",
    "- **Exploring** subsets (filtering by conditions),\n",
    "- **Training ML models** (splitting and shuffling), and\n",
    "- **Augmenting** datasets (adding new records).\n",
    "\n",
    "Row operations are performed using `iloc`, `loc`, `drop()`, `concat()`, `sample()`, filtering expressions, and slicing. They help us get our data into the right shape and form for analysis or modeling.\n",
    "\n",
    "### Why Row Operations Are Important\n",
    "\n",
    "Row-level operations are essential in nearly every data science project because:\n",
    "\n",
    "- **Cleaning**: Drop irrelevant, null, or duplicate rows.\n",
    "- **Exploration**: Filter rows by age, survival, or fare.\n",
    "- **Testing**: Sample small random subsets.\n",
    "- **Reordering**: Shuffle for cross-validation or visual sanity checks.\n",
    "- **Expansion**: Add test cases or new rows programmatically.\n",
    "\n",
    "In real-world projects, row manipulations help transform messy or unstructured data into clean, usable tables that work well with ML algorithms.\n",
    "\n",
    "### Common Row Operations and Syntax\n",
    "\n",
    "1. **Adding Rows (`pd.concat()` instead of `.append()`)**\n",
    "    \n",
    "    Since **Pandas 2.0**, `.append()` is **deprecated**, so use `pd.concat()` to add rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d8980a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass                                      Name  \\\n",
      "887          888         1       1              Graham, Miss. Margaret Edith   \n",
      "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "889          890         1       1                     Behr, Mr. Karl Howell   \n",
      "890          891         0       3                       Dooley, Mr. Patrick   \n",
      "891          999         0       3                           Test, Mr. Dummy   \n",
      "\n",
      "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
      "887  female  19.0      0      0      112053  30.00   B42        S  \n",
      "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
      "889    male  26.0      0      0      111369  30.00  C148        C  \n",
      "890    male  32.0      0      0      370376   7.75   NaN        Q  \n",
      "891    male  30.0      0      0      000000   7.25  None        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# Create a new row (same column structure)\n",
    "new_row = pd.DataFrame([{\n",
    "    'PassengerId': 999,\n",
    "    'Survived': 0,\n",
    "    'Pclass': 3,\n",
    "    'Name': 'Test, Mr. Dummy',\n",
    "    'Sex': 'male',\n",
    "    'Age': 30,\n",
    "    'SibSp': 0,\n",
    "    'Parch': 0,\n",
    "    'Ticket': '000000',\n",
    "    'Fare': 7.25,\n",
    "    'Cabin': None,\n",
    "    'Embarked': 'S'\n",
    "}])\n",
    "\n",
    "# Append using pd.concat\n",
    "df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd6880",
   "metadata": {},
   "source": [
    "2. Removing Rows\n",
    "    \n",
    "    We can remove rows using `.drop()` by index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e7c62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "5            6         0       3   \n",
      "6            7         0       1   \n",
      "7            8         0       3   \n",
      "\n",
      "                                           Name     Sex   Age  SibSp  Parch  \\\n",
      "3  Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0   \n",
      "4                      Allen, Mr. William Henry    male  35.0      0      0   \n",
      "5                              Moran, Mr. James    male   NaN      0      0   \n",
      "6                       McCarthy, Mr. Timothy J    male  54.0      0      0   \n",
      "7                Palsson, Master. Gosta Leonard    male   2.0      3      1   \n",
      "\n",
      "   Ticket     Fare Cabin Embarked  \n",
      "3  113803  53.1000  C123        S  \n",
      "4  373450   8.0500   NaN        S  \n",
      "5  330877   8.4583   NaN        Q  \n",
      "6   17463  51.8625   E46        S  \n",
      "7  349909  21.0750   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "df = df.drop(index=0)  # Remove first row\n",
    "df = df.drop(index=[1, 2])  # Remove multiple rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b383c9d",
   "metadata": {},
   "source": [
    "3. Selecting/Reordering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d455a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "5            6         0       3   \n",
      "6            7         0       1   \n",
      "7            8         0       3   \n",
      "\n",
      "                                           Name     Sex   Age  SibSp  Parch  \\\n",
      "3  Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0   \n",
      "4                      Allen, Mr. William Henry    male  35.0      0      0   \n",
      "5                              Moran, Mr. James    male   NaN      0      0   \n",
      "6                       McCarthy, Mr. Timothy J    male  54.0      0      0   \n",
      "7                Palsson, Master. Gosta Leonard    male   2.0      3      1   \n",
      "\n",
      "   Ticket     Fare Cabin Embarked  \n",
      "3  113803  53.1000  C123        S  \n",
      "4  373450   8.0500   NaN        S  \n",
      "5  330877   8.4583   NaN        Q  \n",
      "6   17463  51.8625   E46        S  \n",
      "7  349909  21.0750   NaN        S  \n",
      "     PassengerId  Survived  Pclass  \\\n",
      "891          999         0       3   \n",
      "890          891         0       3   \n",
      "889          890         1       1   \n",
      "888          889         0       3   \n",
      "887          888         1       1   \n",
      "..           ...       ...     ...   \n",
      "7              8         0       3   \n",
      "6              7         0       1   \n",
      "5              6         0       3   \n",
      "4              5         0       3   \n",
      "3              4         1       1   \n",
      "\n",
      "                                             Name     Sex   Age  SibSp  Parch  \\\n",
      "891                               Test, Mr. Dummy    male  30.0      0      0   \n",
      "890                           Dooley, Mr. Patrick    male  32.0      0      0   \n",
      "889                         Behr, Mr. Karl Howell    male  26.0      0      0   \n",
      "888      Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2   \n",
      "887                  Graham, Miss. Margaret Edith  female  19.0      0      0   \n",
      "..                                            ...     ...   ...    ...    ...   \n",
      "7                  Palsson, Master. Gosta Leonard    male   2.0      3      1   \n",
      "6                         McCarthy, Mr. Timothy J    male  54.0      0      0   \n",
      "5                                Moran, Mr. James    male   NaN      0      0   \n",
      "4                        Allen, Mr. William Henry    male  35.0      0      0   \n",
      "3    Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0   \n",
      "\n",
      "         Ticket     Fare Cabin Embarked  \n",
      "891      000000   7.2500  None        S  \n",
      "890      370376   7.7500   NaN        Q  \n",
      "889      111369  30.0000  C148        C  \n",
      "888  W./C. 6607  23.4500   NaN        S  \n",
      "887      112053  30.0000   B42        S  \n",
      "..          ...      ...   ...      ...  \n",
      "7        349909  21.0750   NaN        S  \n",
      "6         17463  51.8625   E46        S  \n",
      "5        330877   8.4583   NaN        Q  \n",
      "4        373450   8.0500   NaN        S  \n",
      "3        113803  53.1000  C123        S  \n",
      "\n",
      "[889 rows x 12 columns]\n",
      "     PassengerId  Survived  Pclass  \\\n",
      "3              4         1       1   \n",
      "8              9         1       3   \n",
      "9             10         1       2   \n",
      "10            11         1       3   \n",
      "11            12         1       1   \n",
      "..           ...       ...     ...   \n",
      "880          881         1       2   \n",
      "882          883         0       3   \n",
      "885          886         0       3   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
      "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
      "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
      "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "\n",
      "     Parch      Ticket     Fare Cabin Embarked  \n",
      "3        0      113803  53.1000  C123        S  \n",
      "8        2      347742  11.1333   NaN        S  \n",
      "9        0      237736  30.0708   NaN        C  \n",
      "10       1     PP 9549  16.7000    G6        S  \n",
      "11       0      113783  26.5500  C103        S  \n",
      "..     ...         ...      ...   ...      ...  \n",
      "880      1      230433  26.0000   NaN        S  \n",
      "882      0        7552  10.5167   NaN        S  \n",
      "885      5      382652  29.1250   NaN        Q  \n",
      "887      0      112053  30.0000   B42        S  \n",
      "888      2  W./C. 6607  23.4500   NaN        S  \n",
      "\n",
      "[312 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# First 5 rows\n",
    "df_first_5 = df.iloc[:5]\n",
    "print(df_first_5)\n",
    "\n",
    "# Reversed DataFrame\n",
    "df_reversed = df.iloc[::-1]\n",
    "print(df_reversed)\n",
    "\n",
    "# Filter: Only female passengers\n",
    "df_females = df[df['Sex'] == 'female']\n",
    "print(df_females)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96caa016",
   "metadata": {},
   "source": [
    "4. Sampling Rows (Random Subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a401e30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId                                   Name     Sex\n",
      "283          284             Dorking, Mr. Edward Arthur    male\n",
      "437          438  Richards, Mrs. Sidney (Emily Hocking)  female\n",
      "42            43                    Kraeff, Mr. Theodor    male\n",
      "420          421                 Gheorgheff, Mr. Stanio    male\n",
      "587          588       Frolicher-Stehli, Mr. Maxmillian    male\n"
     ]
    }
   ],
   "source": [
    "# Sample 5 random rows\n",
    "df_sample = df.sample(n=5, random_state=42)\n",
    "print(df_sample[['PassengerId', 'Name', 'Sex']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab42bc0",
   "metadata": {},
   "source": [
    "Useful for testing ML models or previewing random data entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba8d27",
   "metadata": {},
   "source": [
    "### Real-World Use Cases\n",
    "\n",
    "| Scenario | Row Operation |\n",
    "| --- | --- |\n",
    "| Remove null values | `df.dropna()` |\n",
    "| Remove duplicates | `df.drop_duplicates()` |\n",
    "| Filter passengers over 60 | `df[df['Age'] > 60]` |\n",
    "| Random 80% for training | `df.sample(frac=0.8)` |\n",
    "| Shuffle dataset | `df.sample(frac=1)` |\n",
    "| Add test data | `pd.concat([df, test_df])` |\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "| Task | Best Practice |\n",
    "| --- | --- |\n",
    "| Adding rows | Use `pd.concat()`, not `.append()` (deprecated) |\n",
    "| Dropping rows | Use `.drop(index=X)` or conditional filtering |\n",
    "| Random sampling | Always use `random_state` for reproducibility |\n",
    "| After drops | Use `.reset_index(drop=True)` if needed |\n",
    "| Avoid inplace confusion | Reassign or use `.copy()` for clarity |\n",
    "\n",
    "### Exercises\n",
    "\n",
    "Q1. Add a dummy row to the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2607c3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass                                      Name  \\\n",
      "885          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "886          890         1       1                     Behr, Mr. Karl Howell   \n",
      "887          891         0       3                       Dooley, Mr. Patrick   \n",
      "888          999         0       3                           Test, Mr. Dummy   \n",
      "889         1000         1       2                         AI, Mr. Synthetic   \n",
      "\n",
      "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
      "885  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
      "886    male  26.0      0      0      111369  30.00  C148        C  \n",
      "887    male  32.0      0      0      370376   7.75   NaN        Q  \n",
      "888    male  30.0      0      0      000000   7.25  None        S  \n",
      "889    male  33.0      0      0    TEST1000  12.50  None        C  \n"
     ]
    }
   ],
   "source": [
    "dummy = pd.DataFrame([{\n",
    "    'PassengerId': 1000,\n",
    "    'Survived': 1,\n",
    "    'Pclass': 2,\n",
    "    'Name': 'AI, Mr. Synthetic',\n",
    "    'Sex': 'male',\n",
    "    'Age': 33,\n",
    "    'SibSp': 0,\n",
    "    'Parch': 0,\n",
    "    'Ticket': 'TEST1000',\n",
    "    'Fare': 12.5,\n",
    "    'Cabin': None,\n",
    "    'Embarked': 'C'\n",
    "}])\n",
    "df = pd.concat([df, dummy], ignore_index=True)\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dccf08",
   "metadata": {},
   "source": [
    "Q2. Drop all rows where Age < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb2d000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            4         1       1   \n",
      "1            5         0       3   \n",
      "3            7         0       1   \n",
      "5            9         1       3   \n",
      "6           10         1       2   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "1                           Allen, Mr. William Henry    male  35.0      0   \n",
      "3                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "5  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "6                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "\n",
      "   Parch  Ticket     Fare Cabin Embarked  \n",
      "0      0  113803  53.1000  C123        S  \n",
      "1      0  373450   8.0500   NaN        S  \n",
      "3      0   17463  51.8625   E46        S  \n",
      "5      2  347742  11.1333   NaN        S  \n",
      "6      0  237736  30.0708   NaN        C  \n"
     ]
    }
   ],
   "source": [
    "df = df[df['Age'] >= 10]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ec5cd",
   "metadata": {},
   "source": [
    "Q3. Shuffle all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc131c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0          880         1       1   \n",
      "1          371         1       1   \n",
      "2          363         0       3   \n",
      "3          688         0       3   \n",
      "4          109         0       3   \n",
      "\n",
      "                                            Name     Sex   Age  SibSp  Parch  \\\n",
      "0  Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0      1   \n",
      "1                    Harder, Mr. George Achilles    male  25.0      1      0   \n",
      "2                Barbara, Mrs. (Catherine David)  female  45.0      0      1   \n",
      "3                              Dakic, Mr. Branko    male  19.0      0      0   \n",
      "4                                Rekic, Mr. Tido    male  38.0      0      0   \n",
      "\n",
      "   Ticket     Fare Cabin Embarked  \n",
      "0   11767  83.1583   C50        C  \n",
      "1   11765  55.4417   E50        C  \n",
      "2    2691  14.4542   NaN        C  \n",
      "3  349228  10.1708   NaN        S  \n",
      "4  349249   7.8958   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29862bd",
   "metadata": {},
   "source": [
    "Q4. Sample 5 random rows showing Name and Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad0f9f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Name     Fare\n",
      "272  Louch, Mrs. Charles Alexander (Alice Adelaide ...  26.0000\n",
      "638                          Madsen, Mr. Fridtjof Arne   7.1417\n",
      "436                          Carr, Miss. Helen \"Ellen\"   7.7500\n",
      "285                    Reuchlin, Jonkheer. John George   0.0000\n",
      "361                  Beane, Mrs. Edward (Ethel Clarke)  26.0000\n"
     ]
    }
   ],
   "source": [
    "print(df.sample(n=5)[['Name', 'Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c3693e",
   "metadata": {},
   "source": [
    "Q5. Remove last 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511a7e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass                               Name     Sex  \\\n",
      "644          848         0       3                 Markoff, Mr. Marin    male   \n",
      "645           36         0       1     Holverson, Mr. Alexander Oskar    male   \n",
      "646          107         1       3   Salkjelsvik, Miss. Anna Kristine  female   \n",
      "647          150         0       2  Byles, Rev. Thomas Roussel Davids    male   \n",
      "648          379         0       3                Betros, Mr. Tannous    male   \n",
      "\n",
      "      Age  SibSp  Parch  Ticket     Fare Cabin Embarked  \n",
      "644  35.0      0      0  349213   7.8958   NaN        C  \n",
      "645  42.0      1      0  113789  52.0000   NaN        S  \n",
      "646  21.0      0      0  343120   7.6500   NaN        S  \n",
      "647  42.0      0      0  244310  13.0000   NaN        S  \n",
      "648  20.0      0      0    2648   4.0125   NaN        C  \n"
     ]
    }
   ],
   "source": [
    "df = df[:-2]\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d26f7",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Row operations form the backbone of real-world data preprocessing. Every row represents one observation (like a person, event, or transaction), and being able to **select, remove, add, or shuffle** these rows efficiently is key to clean and accurate analysis.\n",
    "\n",
    "Adding rows helps in augmenting datasets or including synthetic test data. In modern Pandas (v2.0+), it’s recommended to use `pd.concat()` for this purpose — the `.append()` method is now deprecated and will be removed in future versions.\n",
    "\n",
    "Removing rows is common during cleaning — to eliminate outliers, rows with nulls, or duplicate records. Conditional filters (`df[df[‘col’] > X]`) or `.drop(index=…)` allow us to do this surgically and precisely.\n",
    "\n",
    "Another crucial operation is **random sampling** using `.sample()` — perfect for small previews, test sets, or splitting training/validation datasets. Always use `random_state` to ensure reproducibility.\n",
    "\n",
    "Reordering and slicing (`iloc`, `loc`) is useful for inspection, feature testing, and batch processing. Don’t forget to `.reset_index(drop=True)` if we shuffle or drop rows and need a clean index.\n",
    "\n",
    "These simple but powerful row techniques appear in nearly every data science or ML project — from loading data to exporting final predictions. Whether we're cleaning Titanic data or preparing million-row datasets, row-level control gives us the precision we need to build reliable and scalable data pipelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
