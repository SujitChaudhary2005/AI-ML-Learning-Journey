{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7efa0ce9",
   "metadata": {},
   "source": [
    "# Understanding Data Types and Type Conversion in Pandas\n",
    "\n",
    "### What Are Data Types in Pandas?\n",
    "\n",
    "When we load a dataset using Pandas, each column automatically gets assigned a **data type** based on its contents. These data types (also called `dtypes`) define how Pandas stores and processes the values inside each column. The main types we encounter are:\n",
    "\n",
    "- `int64`: for whole numbers (e.g., 1, 2, 100)\n",
    "- `float64`: for decimal numbers (e.g., 3.14, 75.5)\n",
    "- `object`: usually for text or mixed types (e.g., names, categories)\n",
    "- `bool`: for `True` or `False` values\n",
    "- `datetime64`: for date and time information\n",
    "\n",
    "Understanding data types is **essential** in data science because they control how we clean, analyze, and transform our data. For example, if we try to calculate the average of a column marked as `object`, it will fail — even if the values inside look like numbers. Also, machine learning models can only accept numerical or encoded inputs, so converting types is a key step in data preparation.\n",
    "\n",
    "By learning how to **view**, **interpret**, and **convert** data types properly, we build cleaner, faster, and more reliable pipelines. The Titanic dataset is a great place to practice this, as it contains a mix of numeric, categorical, and missing values.\n",
    "\n",
    "### Checking Data Types with `.dtypes`\n",
    "\n",
    "We can use `.dtypes` to inspect the data type of each column in our DataFrame. This gives us a quick overview of how Pandas has interpreted the dataset. Let’s use it on the Titanic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae9ee904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f451128",
   "metadata": {},
   "source": [
    "### Converting Data Types with `.astype()`\n",
    "\n",
    "Sometimes, Pandas guesses the wrong data type, or we want to convert it manually — for example, turning a float into an integer, or a numeric column into a category. We can use the `.astype()` method to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5efbadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived          bool\n",
      "Pclass          object\n",
      "Name            object\n",
      "Sex             object\n",
      "Age              int64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Pclass' to string (useful for treating it like a category)\n",
    "df['Pclass'] = df['Pclass'].astype(str)\n",
    "\n",
    "# Convert 'Survived' to boolean\n",
    "df['Survived'] = df['Survived'].astype(bool)\n",
    "\n",
    "# Convert 'Age' to integer (only if we know there are no decimals or missing values)\n",
    "df['Age'] = df['Age'].fillna(0).astype(int)\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25e0930",
   "metadata": {},
   "source": [
    "This approach gives us full control over how columns are interpreted. But we must be careful — converting without handling `NaN` values or mismatched types can throw errors.\n",
    "\n",
    "### Converting to Datetime with `pd.to_datetime()`\n",
    "\n",
    "When working with date columns (like timestamps, birthdates, or logs), we use the `pd.to_datetime()` function to convert a column to the `datetime64` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89045495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Name        DOB\n",
      "0                            Braund, Mr. Owen Harris 1980-01-01\n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th... 1975-05-23\n",
      "2                             Heikkinen, Miss. Laina 1990-07-15\n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel) 1985-12-30\n",
      "4                           Allen, Mr. William Henry 1978-03-10\n"
     ]
    }
   ],
   "source": [
    "# Add a sample 'DOB' column with string dates\n",
    "df['DOB'] = ['1980-01-01', '1975-05-23', '1990-07-15', '1985-12-30', '1978-03-10'] + ['1982-06-18'] * (len(df) - 5)\n",
    "\n",
    "# Convert 'DOB' to datetime\n",
    "df['DOB'] = pd.to_datetime(df['DOB'])\n",
    "\n",
    "print(df[['Name', 'DOB']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72624463",
   "metadata": {},
   "source": [
    "This conversion unlocks new possibilities — we can extract day, month, year, weekday, and perform date-based calculations.\n",
    "\n",
    "### Detecting Columns by Type\n",
    "\n",
    "Sometimes we want to know **how many columns are int, float, or object** types. We can do this with `.select_dtypes()` and `.dtypes.value_counts()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0dd6dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object            6\n",
      "int64             4\n",
      "bool              1\n",
      "float64           1\n",
      "datetime64[ns]    1\n",
      "Name: count, dtype: int64\n",
      "Integer columns:\n",
      " Index(['PassengerId', 'Age', 'SibSp', 'Parch'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Count how many columns are of each data type\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# OR select specific types\n",
    "int_cols = df.select_dtypes(include='int64')\n",
    "print(\"Integer columns:\\n\", int_cols.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe67ba",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Q1. Load the Titanic dataset and print the data types of all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8dbdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a35a8a0",
   "metadata": {},
   "source": [
    "Q2. Convert the 'Pclass' column to a string type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c493b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3\n",
      "1    1\n",
      "2    3\n",
      "3    1\n",
      "4    3\n",
      "Name: Pclass, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data['Pclass'] = data['Pclass'].astype(str)\n",
    "print(data['Pclass'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8089e9b",
   "metadata": {},
   "source": [
    "Q3. Convert the 'Survived' column to a boolean type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "804d127a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "Name: Survived, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "data['Survived'] = data['Survived'].astype(bool)\n",
    "print(data['Survived'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a573197e",
   "metadata": {},
   "source": [
    "Q4. Convert the 'Age' column to integers (first fill missing values with 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c4ac56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22\n",
      "1    38\n",
      "2    26\n",
      "3    35\n",
      "4    35\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data['Age'] = data['Age'].fillna(0).astype(int)\n",
    "print(data['Age'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b49b115",
   "metadata": {},
   "source": [
    "Q5. Print the count of columns by data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb56ab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     6\n",
      "int64      4\n",
      "bool       1\n",
      "float64    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595e96fe",
   "metadata": {},
   "source": [
    "Q6. Print the names of all float-type columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "774b0c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Fare'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "float_columns = data.select_dtypes(include='float64').columns\n",
    "print(float_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cd15f1",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this topic, we explored one of the most fundamental yet often overlooked areas of working with Pandas — **data types**. Every column in a DataFrame has a `dtype`, and knowing what it is (and why it matters) helps us avoid unexpected bugs and incorrect results.\n",
    "\n",
    "We learned that `.dtypes` gives us a full snapshot of our dataset’s structure. We used `.astype()` to manually convert between `int`, `float`, `bool`, and `object`, and we practiced safe type conversion using `fillna()` to handle missing values. We also explored how to analyze our dataset by type using `.select_dtypes()` and `.dtypes.value_counts()`.\n",
    "\n",
    "Mastering these techniques ensures that our data is ready for the next steps — including encoding, scaling, modeling, and visualization. In real AI/ML projects, cleaning and converting data types is a task we do all the time. The better we get at this, the faster and cleaner our workflows become."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
